#!/usr/bin/env python3
"""
Script thÃªm khuÃ´n máº·t thá»§ cÃ´ng vÃ o AI database
"""

import cv2
import os
import time
import numpy as np
from improved_face_recognition import ImprovedFaceRecognition

def add_face_manual():
    print("ğŸ¤– THÃŠM KHUÃ”N Máº¶T VÃ€O AI DATABASE")
    print("=" * 50)
    
    # Khá»Ÿi táº¡o face recognizer
    face_recognizer = ImprovedFaceRecognition(
        models_path="/home/khoi/Desktop/KHOI_LUANAN/models",
        face_data_path="/home/khoi/Desktop/KHOI_LUANAN/face_data"
    )
    
    # Nháº­p tÃªn
    name = input("ğŸ‘¤ Nháº­p tÃªn cá»§a báº¡n: ").strip()
    if not name:
        print("âŒ TÃªn khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")
        return
    
    print(f"ğŸ“¸ Sáº½ chá»¥p 25 áº£nh training cho: {name}")
    print("ğŸ‘ï¸ HÆ°á»›ng dáº«n:")
    print("   - NhÃ¬n tháº³ng vÃ o camera")
    print("   - Di chuyá»ƒn Ä‘áº§u nháº¹ (trÃ¡i, pháº£i, lÃªn, xuá»‘ng)")
    print("   - Äáº£m báº£o Ã¡nh sÃ¡ng tá»‘t")
    print("   - Báº¥m SPACE Ä‘á»ƒ chá»¥p, ESC Ä‘á»ƒ thoÃ¡t")
    print()
    
    # Khá»Ÿi táº¡o camera
    try:
        from picamera2 import Picamera2
        camera = Picamera2()
        camera.configure(camera.create_video_configuration(
            main={"format": 'XRGB8888', "size": (800, 600)}
        ))
        camera.start()
        time.sleep(2)
        print("âœ… Camera sáºµn sÃ ng!")
    except:
        print("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o camera!")
        return
    
    captured_images = []
    target_images = 25
    
    try:
        while len(captured_images) < target_images:
            # Capture frame
            frame = camera.capture_array()
            if frame is None:
                continue
            
            # Hiá»ƒn thá»‹ frame
            display_frame = cv2.resize(frame, (640, 480))
            cv2.putText(display_frame, f"Training: {name}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(display_frame, f"Images: {len(captured_images)}/{target_images}", (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv2.putText(display_frame, "SPACE: Capture | ESC: Exit", (10, 450), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # Detect faces Ä‘á»ƒ hiá»ƒn thá»‹ khung
            faces = face_recognizer.detect_faces(frame)
            for (x, y, w, h) in faces:
                # Scale coordinates for display
                scale_x = 640 / 800
                scale_y = 480 / 600
                x_scaled = int(x * scale_x)
                y_scaled = int(y * scale_y)
                w_scaled = int(w * scale_x)
                h_scaled = int(h * scale_y)
                
                cv2.rectangle(display_frame, (x_scaled, y_scaled), 
                             (x_scaled + w_scaled, y_scaled + h_scaled), (0, 255, 0), 2)
                cv2.putText(display_frame, "Face Detected", (x_scaled, y_scaled-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            cv2.imshow('AI Face Training', display_frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord(' '):  # Space to capture
                if faces:
                    # Capture training image
                    training_images = face_recognizer.capture_training_images(frame, 1)
                    if training_images:
                        captured_images.extend(training_images)
                        print(f"ğŸ“¸ Captured image {len(captured_images)}/{target_images}")
                        
                        # Visual feedback
                        cv2.rectangle(display_frame, (0, 0), (640, 480), (0, 255, 0), 5)
                        cv2.imshow('AI Face Training', display_frame)
                        cv2.waitKey(200)  # Flash effect
                    else:
                        print("âŒ KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t rÃµ rÃ ng!")
                else:
                    print("âŒ KhÃ´ng cÃ³ khuÃ´n máº·t trong khung hÃ¬nh!")
                    
            elif key == 27:  # ESC to exit
                print("ğŸ”„ ThoÃ¡t training...")
                break
                
            time.sleep(0.1)
        
        cv2.destroyAllWindows()
        camera.stop()
        
        if len(captured_images) >= 15:
            print(f"\nğŸ§  Äang xá»­ lÃ½ {len(captured_images)} áº£nh training...")
            
            if face_recognizer.add_person(name, captured_images):
                print("âœ… TRAINING THÃ€NH CÃ”NG!")
                print(f"ğŸ‘¤ ÄÃ£ thÃªm {name} vÃ o AI database")
                print(f"ğŸ“¸ Vá»›i {len(captured_images)} áº£nh training")
                
                # Hiá»ƒn thá»‹ thá»‘ng kÃª
                info = face_recognizer.get_database_info()
                print(f"\nğŸ“Š THá»NG KÃŠ DATABASE:")
                print(f"   ğŸ‘¥ Tá»•ng sá»‘ ngÆ°á»i: {info['total_people']}")
                print(f"   ğŸ“¸ Tá»•ng áº£nh: {sum(p['face_count'] for p in info['people'].values())}")
                return True
            else:
                print("âŒ Lá»—i lÆ°u dá»¯ liá»‡u training!")
        else:
            print(f"âŒ KhÃ´ng Ä‘á»§ áº£nh training! Cáº§n Ã­t nháº¥t 15 áº£nh, cÃ³ {len(captured_images)}")
            
    except Exception as e:
        print(f"âŒ Lá»—i training: {e}")
    finally:
        cv2.destroyAllWindows()
        if 'camera' in locals():
            camera.stop()
    
    return False

if __name__ == "__main__":
    add_face_manual()
